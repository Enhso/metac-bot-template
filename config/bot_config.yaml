# Bot configuration for EnsembleForecaster
# You can override the path with: python main.py --config config/bot_config.yaml

bot:
  research_reports_per_question: 3
  predictions_per_research_report: 1
  use_research_summary_to_forecast: false
  publish_reports_to_metaculus: true
  folder_to_save_reports_to: "./forecast_reports"
  skip_previously_forecasted_questions: true

llms:
  default:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 1024

  initial_pred_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  critique_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  refined_pred_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  keyword_extractor_llm:
    type: general
    model: "openrouter/deepseek/deepseek-chat-v3.1:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 1024

  summarizer:
    type: general
    model: "openrouter/deepseek/deepseek-chat-v3.1:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 4096

  parser:
    type: general
    model: "openrouter/deepseek/deepseek-chat-v3.1:free"
    max_tokens: 2048

  researcher: "asknews/deep-research/high-depth"

  # Per-persona LLM assignments for maximum cognitive diversity
  persona_skeptic_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_proponent_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_quant_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_contrarian_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_systems_thinker_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_red_team_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_historian_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_technologist_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_behavioral_economist_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  persona_geopolitical_strategist_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  # Specialized LLM for contradictory information analysis
  contradiction_analyzer_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  # Specialized LLM for volatility analysis
  volatility_analyzer_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192

  bias_checker_llm:
    type: general
    model: "openrouter/deepseek/deepseek-r1-0528:free"
    timeout: 80
    allowed_tries: 2
    max_tokens: 8192
